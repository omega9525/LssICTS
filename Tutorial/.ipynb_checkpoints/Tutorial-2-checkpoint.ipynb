{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font size =10 color='black'> LSS Hand On: session 2 </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "#####importing the necessary libraries\n",
    "#To make the plots inline otherwise it will make seperate figure\n",
    "%matplotlib inline \n",
    "#for high resolution plot outputs\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "import fitsio as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font size =10 color='red'> Cosmology - The Next Decade </font> \n",
    " \n",
    "# <font size=6 color='blue'> International Center for Theoretical Science , Bangalore </font>\n",
    "\n",
    "##  <font size=3 color='black'> Author: Shadab Alam (salam@roe.ac.uk) </font>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font size=6 color='blue'> Today's Goal: Simulated galaxy catalog and Real data </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# What is Dark Matter only N-body Cosmological Simulation?\n",
    "\n",
    "Show the video on wiki and Leacy simulation video\n",
    "https://en.wikipedia.org/wiki/File:N-body_Simulation.ogv\n",
    "\n",
    "\n",
    "# Dark Matter Haloes?\n",
    "\n",
    "# Galaxies (HOD)\n",
    "\n",
    "# Simulated Galaxy Catalogue\n",
    "datafile='/Users/shock/Documents/talks/ICTS2019/Tutorial/data/HOD_cat_model-bolshoi-ICTS-1.gcat'\n",
    "\n",
    "# Correlation function\n",
    "$$ \\xi(r) = \\frac{DD(r)}{ RR(r)} -1 $$\n",
    "\n",
    "# Landy-Szalay Estimator\n",
    "$$\\xi(r) = \\frac{DD(r) - 2*DR(r) + RR(r)}{RR(r)} $$\n",
    "\n",
    "# Measure 3D clustering  in 2D space\n",
    "\n",
    "<img src=\"../images/measure-2D-clustering.png\" alt=\"drawing\" width=\"1000\"/>\n",
    "\n",
    "$$\\xi(r_\\perp,r_\\parallel) = \\frac{DD((r_\\perp,r_\\parallel) - 2DR((r_\\perp,r_\\parallel) + RR((r_\\perp,r_\\parallel)}{RR((r_\\perp,r_\\parallel)} $$\n",
    "\n",
    "# Measure 2D clustering in redshift space and make plots\n",
    "\n",
    "There are several publicly available codes to measure correlation function. The goal here is not to understand how you will write such a code but rather what are the decision one need to make. Once you understand those decisions then you can download and use any of the publicly available code pretty easily.\n",
    "We will be internally using this code written by me:\n",
    "https://gitlab.com/shadaba/CorrelationFunction\n",
    "\n",
    "\n",
    "We will be using following function to do our measurement, lets try to understand its signature first and use it once to measure the correlation function of galaxies in a simulated catalogue\n",
    "\n",
    "our simulated catalogue of galaxies is in this file:\n",
    "# datafile='../data/HOD_cat_model-bolshoi-ICTS-1.gcat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xi(datafile,rlim=[0,20,-20,20],nbins=[30,40],Lbox=250.0,\n",
    "                  POS_min=[0,0,0],sampmode=1,njn=0,pbc=1,los=1,interactive=1,plots=0,rsd=0,\n",
    "                  randfile='',filetype='txt',randfactor=2):\n",
    "    \n",
    "    ''' This measures the correlation function \n",
    "    sampmode= 0=rmu , 1=rpara-rperp, 2=rtheta, \n",
    "    3=log(rpar)-rperp (The range of r_perp in samplim should be entered in the log space), \n",
    "    4=log(r)-theta (The range of r in samplim should be entered in the log space)\n",
    "    randfactor: number of times randoms compared to galaxies'''\n",
    "    \n",
    "\n",
    "    comm='../CorrelationFunction/Runme_Correlation.py'\n",
    "    comm='%s -data %s'%(comm,datafile)\n",
    "    \n",
    "    if(randfile!=''):\n",
    "        comm='%s -rand %s -randfactor %d'%(comm,randfile,randfactor)\n",
    "        RRtype=''\n",
    "    #elif(njn==0):\n",
    "    #    comm='%s -rand norand -randfactor 2'%(comm)\n",
    "    #    RRtype='norand'\n",
    "    elif(np.int(np.sqrt(njn))!=np.sqrt(njn)):\n",
    "        print('njn must be a perfect square but it is not %d'%njn)\n",
    "        sys.exit()\n",
    "    else:\n",
    "        comm='%s -rand generate -randfactor %d'%(comm,randfactor)\n",
    "        RRtype=''\n",
    "        \n",
    "    comm='%s -sampmode %d -samplim %f %f %f %f'%(comm,sampmode,rlim[0],rlim[1],rlim[2],rlim[3])\n",
    "    comm='%s -nbins %d %d'%(comm,nbins[0],nbins[1])\n",
    "    comm='%s -pbc %d -los %d -Lbox %f -outfile tmp/PairCount/tmp'%(comm,pbc,los,Lbox)\n",
    "    comm='%s -RSD %d -njn %d -filetype %s -nproc 4'%(comm,rsd,njn,filetype)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    print(comm)\n",
    "    #execute the command\n",
    "    !python $comm\n",
    "    \n",
    "    #convert pair count to xi\n",
    "    if(False):\n",
    "        pxi_comm='../CorrelationFunction/PairCountTOxi.py'\n",
    "        pxi_comm='%s -sampmode %d -njn %d -Lbox %f'%(pxi_comm,sampmode,njn,Lbox)\n",
    "        pxi_comm='%s -pcroot tmp/PairCount/tmp'%(pxi_comm)\n",
    "        pxi_comm='%s  -xi2droot tmp/XI2D/tmp'%(pxi_comm)\n",
    "        pxi_comm='%s -xi02root tmp/WP/tmp'%(pxi_comm)\n",
    "        if(RRtype!=''):\n",
    "            pxi_comm='%s -RRtype %s'%(pxi_comm,RRtype)\n",
    "\n",
    "        #pxi_comm='%s '%(pxi_comm)   \n",
    "        !python $pxi_comm\n",
    "    \n",
    "    \n",
    "    #load result in dictionary\n",
    "    xi_dic={}\n",
    "    if(sampmode in [1,3]):\n",
    "        xi_dic['rpar_ed']=np.linspace(rlim[2],rlim[3],nbins[1]+1)\n",
    "        xi_dic['rper_ed']=np.linspace(rlim[0],rlim[1],nbins[0]+1)\n",
    "        if(sampmode==3):\n",
    "            xi_dic['rper_ed']=np.power(10,xi_dic['rper_ed'])\n",
    "            \n",
    "        xi_dic['rpar']=0.5*(xi_dic['rpar_ed'][1:]+xi_dic['rpar_ed'][:-1])\n",
    "        xi_dic['rper']=0.5*(xi_dic['rper_ed'][1:]+xi_dic['rper_ed'][:-1])\n",
    "        xi2d=np.loadtxt('tmp/XI2D/tmp-rp-pi-NJN-%d.txt'%njn)\n",
    "        if(njn!=0):\n",
    "            xi2d=xi2d[:,0]\n",
    "    \n",
    "        xi2d=np.transpose(xi2d.reshape(nbins[0],nbins[1]))\n",
    "        xi_dic['xi2d']=np.column_stack([xi2d[:,::-1],xi2d])\n",
    "        xi_dic['rper']=np.append(-xi_dic['rper'][::-1],xi_dic['rper'])\n",
    "        \n",
    "        #load wp\n",
    "        xi_dic['wp']=np.loadtxt('tmp/WP/tmp-wp-rp-pi-NJN-%d.txt'%njn)\n",
    "        \n",
    "    if(sampmode ==0):\n",
    "        xi_dic['r3d_ed']=np.linspace(rlim[2],rlim[3],nbins[1]+1)\n",
    "        xi_dic['mu_ed']=np.linspace(rlim[0],rlim[1],nbins[0]+1)\n",
    "        \n",
    "        xi_dic['r3d']=0.5*(xi_dic['r3d_ed'][1:]+xi_dic['r3d_ed'][:-1])\n",
    "        xi_dic['mu']=0.5*(xi_dic['mu_ed'][1:]+xi_dic['mu_ed'][:-1])\n",
    "        xi2d=np.loadtxt('tmp/XI2D/tmp-rmu-NJN-%d.txt'%njn)\n",
    "        if(njn!=0):\n",
    "            xi2d=xi2d[:,0]\n",
    "            \n",
    "        xi_dic['xi2d']=np.transpose(xi2d.reshape(nbins[0],nbins[1]))\n",
    "        \n",
    "        #load xi0/xi2\n",
    "        xi_dic['xi0']=np.loadtxt('tmp/XI02/tmp-xi0-rmu-NJN-%d.txt'%njn)\n",
    "        xi_dic['xi2']=np.loadtxt('tmp/XI02/tmp-xi2-rmu-NJN-%d.txt'%njn)\n",
    "        \n",
    "    return xi_dic\n",
    "\n",
    "def draw_circle(radius=1.0,color='r'):\n",
    "    xx=np.linspace(0,radius,30)\n",
    "    yy=np.sqrt(np.power(radius,2)-np.power(xx,2))\n",
    "    \n",
    "    pl.plot(xx,yy,'-',color=color)\n",
    "    pl.plot(-xx,yy,'-',color=color)\n",
    "    pl.plot(-xx,-yy,'-',color=color)\n",
    "    pl.plot(xx,-yy,'-',color=color)\n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explain following things:\n",
    "1) get_xi function signature with rlims, nbins, Lbox\n",
    "     $$rlims=[r_{\\perp}^{min}, r_{\\perp}^{max},r_{\\parallel}^{min}, r_{\\parallel}^{max}]$$\n",
    "     $$nbins=[\\text{number of bins in the first axis}, \\text{number of bins in the second axis}] $$\n",
    "     $$L_{box}= 250$$\n",
    "\n",
    "2) python dictionary including xi2d, rper and rpar\n",
    "\n",
    "3) pl.imshow\n",
    "\n",
    "\n",
    "# <font size=5, color='blue'> Work 1 (10 minutes): Measure the clustering of simulation </font>\n",
    "Now write the code to measure the 2D correlation function of simulated galaxy catalogue using the function\n",
    "<font size=3, color='green'> get_xi</font>\n",
    "\n",
    "and plot the measured clustering. You should measure the clustering for rper 0-30 (Mpc/h)and rpar -30 to 30 (Mpc/h).\n",
    "\n",
    "Also draw a circle of certain radius to compare the contours with circle.\n",
    "\n",
    "# use the cells below to write and execute the code you can create new cells by clicking on the + sign on the top panel below File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solution to work 1 part 1 : call get_xi to measure clustering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solution to work 1 part 2: make a 2d plot of clustering with contours and also draw a circle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How will the clustering look like with redshift space distortion?\n",
    "\n",
    "\n",
    "# <font size=5, color='blue'> Work 2 (10 minutes): Redshift Space correlation function </font>\n",
    "move galaxies to their redshift space position by setting rsd=1 in get_xi and measure the clustering signal again.\n",
    "Make a plot to compare this with your previous plot. Also draw a circle of radius 10 on top of the correlation function to see if this is symmetric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solution to work 2 part 1 : measure clustering in redshift space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solution to work 2 part 2: make plots\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multipole expansion\n",
    "\n",
    "<img src=\"../images/multipole-expansion.png\" alt=\"drawing\" width=\"1000\"/>\n",
    "\n",
    "# Explain sampmode in get_xi and rlims. Also explain xi0 and xi2 in dictionary\n",
    "\n",
    "# <font size=5, color='blue'> Work 3 (10 minutes): Compute the multipole moments using get_xi in real and redshift space make a plot with pair seperation (r) on x-axis and either r^2 monopole or r^2 Quadruple on the y-axis</font>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solution: Measure clustering multipoles\n",
    "datafile='../data/HOD_cat_model-bolshoi-ICTS-1.gcat'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#solution part 2: make plot of multipoles\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimation of error:\n",
    "There are several methods to quanitfy the error on clustering signal. Typically the simplest and most accurate but computationally expensive methods uses N-body simulations. The computationally least expensive but complex and approximate method use perturbation theory and most popular method uses approximate mocks which are fast simulation using perturbation theory methods.\n",
    "\n",
    "We can also estimate the error from data. Two such methods widely used are know as \"Jakknife\" and \"Bootstrap\". \n",
    "Both of these methods can be shown to work exactly right with known biases if the assumptions are satisfied.\n",
    "But in comoslogical analysis those assumptions are not entirely satisfied and hence these methods can over or under estimate error depending on the situation.\n",
    "\n",
    "# Jackknife errors\n",
    "\n",
    "<img src=\"../images/jackknife-resampling.png\" alt=\"drawing\" width=\"600\"/>\n",
    "\n",
    "$$Var(s_i)= \\frac{(N_{jn}-1)}{N_{jn}}  \\sum_{jn=0}^{jn<njn} (s_{jn,i}- \\bar{s_i}) ^2$$\n",
    "\n",
    "\n",
    "\n",
    "# explain pl.errorbar(x,y,yerr) and njn in get_xi including modified output xi0,xi2\n",
    "\n",
    "# <font size=5, color='blue'> Work 4 (10 minutes): Compute the multipole moments using get_xi in real and redshift space make a plot with pair seperation (r) on x-axis and either r^2 monopole or r^2 Quadruple on the y-axis</font>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure the clustering multipoles with jackknife errors\n",
    "datafile='../data/HOD_cat_model-bolshoi-ICTS-1.gcat'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the multipoles with error bars estimated using pl.errorbar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing a Jackknife covariance matrix\n",
    "\n",
    "\n",
    "# Variance:\n",
    "$$Var(s_i)= \\frac{(N_{jn}-1)}{N_{jn}}  \\sum_{jn=0}^{jn<njn} (s_{jn,i}- \\bar{s_i}) ^2$$\n",
    "\n",
    "# Covariance matrix\n",
    "$$C_{i,j}= \\frac{(N_{jn}-1)}{N_{jn}} \\sum_{jn=0}^{jn<njn} (s_{jn,i}- \\bar{s_i}) \\sum_{jn=0}^{jn<njn} (s_{jn,j}- \\bar{s_j})$$\n",
    "\n",
    "# Correlation matrix\n",
    "$$Corr_{i,j}=\\frac{C_{i,j}}{\\sqrt{C_{i,i}C_{j,j}}}$$\n",
    "\n",
    "# Example covariance matrix of monopole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xi_dic=xi_dic_wrsd\n",
    "#covariance of the monopole\n",
    "njn=xi_dic['xi0'].shape[1]-4\n",
    "\n",
    "covxi0=(njn-1)*np.cov(xi_dic['xi0'][:,4:])\n",
    "\n",
    "pl.figure(figsize=(8,8))\n",
    "pl.imshow(covxi0)\n",
    "pl.colorbar()\n",
    "pl.title('covariance matrix of monopole')\n",
    "\n",
    "corrxi0=np.copy(covxi0)\n",
    "for ii in range(0,covxi0.shape[0]):\n",
    "    for jj in range(0,covxi0.shape[1]):\n",
    "        corrxi0[ii,jj]=covxi0[ii,jj]/(np.sqrt(covxi0[ii,ii])*np.sqrt(covxi0[jj,jj]))\n",
    "\n",
    "pl.figure(figsize=(8,8))\n",
    "pl.imshow(corrxi0,vmin=-1,vmax=1,cmap='seismic')\n",
    "pl.colorbar()       \n",
    "pl.title('correlation matrix of monopole')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# <font size=5, color='blue'> Work 5 (5 minutes): Compute the covariance and correlation matrix of Quadruple moment of the correlation function and make plots</font>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#covariance of the Quadrupole\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined and cross covariance of $\\xi_0$ and $\\xi_2$\n",
    "\n",
    "\n",
    "# <font size=5, color='blue'> Work 6 (10 minutes): Compute the combined covariance and correlation matrix of $\\xi_0$ and $\\xi_2$ and make plots</font>\n",
    "\n",
    "# Hint: use np.row_stack function to make combined array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xi_dic=xi_dic_wrsd\n",
    "#Combined covariance matrix\n",
    "njn=xi_dic['xi2'].shape[1]-4\n",
    "xi02=np.row_stack([xi_dic['xi0'][:,4:],xi_dic['xi2'][:,4:]])\n",
    "\n",
    "covxi2=(njn-1)*np.cov(xi02)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at real data from Sloan Digital Sky Survey (SDSS)\n",
    "\n",
    "#  <font size=5, color='green'> datafile= '../data/LOWZ-all-galaxy.txt' </font>\n",
    "#  <font size=5, color='green'> randomfile= '../data/LOWZ-all-random.txt' </font>\n",
    "\n",
    "\n",
    "# <font size=5, color='blue'> Exploration: (5 minutes) </font>\n",
    "\n",
    "The file has three columns RA,DEC and redshift.\n",
    "load the file using \"np.loadtxt\" which will give you a numpy array and explore the data by making plots and distribution of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#to load the data\n",
    "datafile= '../data/LOWZ-all-galaxy.txt'\n",
    "data=np.loadtxt(datafile)\n",
    "print(data.shape)\n",
    "\n",
    "#make ra,dec plot ra,z , dec,z , also make histograms of ra, dec,redshift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explain following inputs of get_xi\n",
    "\n",
    "randfile='',sampmode=1, pbc=0, njn=0, los=0, rsd=0, filetype='polartxt'\n",
    "\n",
    "# <font size=5, color='blue'> Work 7 (10 minutes): Now compute the clustering of data with rper=0,20 and rpar=-20,20 and make a 2d plot with axis as rper and rpar and the color axis as logarithm of the correlation function also plot contours </font>\n",
    "\n",
    "# Hint: use pl.imshow and pl.contour for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile='../data/LOWZ-all-galaxy.txt'\n",
    "randfile='../data/LOWZ-all-random.txt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#solutione to work 1 part 2: make plot of the clustering with rper,rpar and clustering as color\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font size=5, color='blue'> Work 8 (10 minutes): Now compute monopole and quadruple moment of the correlation function and make plots from data. </font>\n",
    "\n",
    "# Hint: you need to think about sampling axis and limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure the multipole moment of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the multipole moments of data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# <font size=5, color='blue'> Work 9: Now compute the jackknife errors of the multipoles for data. </font>\n",
    "\n",
    "# For the polar file which is how real data is you need to create files with five columns RA,DEC,Z,weight,jackknife number and then rerun the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile='../data/LOWZ-all-galaxy.txt'\n",
    "randfile='../data/LOWZ-all-random.txt'\n",
    "rand=np.loadtxt(randfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.figure(figsize=(10,10))\n",
    "pl.plot(rand[:,0],rand[:,1],'.')\n",
    "pl.xlabel('RA',fontsize=22)\n",
    "pl.ylabel('DEC',fontsize=22)\n",
    "pl.title('SDSS LOWZ sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nbodykit",
   "language": "python",
   "name": "nbodykit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
